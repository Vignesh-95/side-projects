{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a46a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating a graph\n",
    "# passing graphs for evalkuation\n",
    "# techniques vs just passing \n",
    "# and how to do in ui and langsmith\n",
    "# best pracices \n",
    "# E2E\n",
    "# setting up evlauation process and tempaltes - repreocuidble\n",
    "# all the features a framowrk and a platofrm provide!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6e553d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Literal, TypedDict\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "import os\n",
    "import nest_asyncio\n",
    "from langchain.globals import set_debug, set_verbose\n",
    "\n",
    "\n",
    "set_debug(True)\n",
    "set_verbose(True)\n",
    "nest_asyncio.apply()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "os.environ[\"LANGSMITH_TRACING\"] = LANGSMITH_TRACING\n",
    "os.environ[\"LANGSMITH_ENDPOINT\"] = LANGSMITH_ENDPOINT\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = LANGSMITH_API_KEY\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = LANGSMITH_PROJECT\n",
    "os.environ[\"TAVILY_API_KEY\"] = TAVILY_API_KEY\n",
    "os.environ[\"ANTHROPIC_API_KEY\"] = ANTHROPIC_API_KEY\n",
    "\n",
    "class State(TypedDict): # Messages have the type \"list\". The 'add_messages' function # in the annotation defines how this state key should be updated # (in this case, it appends messages to the list, rather than overwriting them)\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# Define the tools for the agent to use\n",
    "@tool\n",
    "def search(query: str) -> str:\n",
    "    \"\"\"Call to surf the web.\"\"\" # This is a placeholder, but don't tell the LLM that...\n",
    "    if \"sf\" in query.lower() or \"san francisco\" in query.lower():\n",
    "        return \"It's 60 degrees and foggy.\"\n",
    "    return \"It's 90 degrees and sunny.\"\n",
    "\n",
    "tools = [search]\n",
    "tool_node = ToolNode(tools)\n",
    "model = init_chat_model(\"claude-3-5-sonnet-latest\").bind_tools(tools)\n",
    "\n",
    "# Define the function that determines whether to continue or not\n",
    "def should_continue(state: State) -> Literal[\"tools\", END]:\n",
    "    messages = state['messages']\n",
    "    last_message = messages[-1] # If the LLM makes a tool call, then we route to the \"tools\" node\n",
    "    if last_message.tool_calls:\n",
    "        return \"tools\" # Otherwise, we stop (reply to the user)\n",
    "    return END\n",
    "\n",
    "# Define the function that calls the model\n",
    "\n",
    "def call_model(state: State):\n",
    "    messages = state['messages']\n",
    "    response = model.invoke(messages) # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "# Define the two nodes we will cycle between\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "\n",
    "# Set the entrypoint as 'agent'\n",
    "# This means that this node is the first one called\n",
    "workflow.add_edge(START, \"agent\")\n",
    "\n",
    "# We now add a conditional edge\n",
    "workflow.add_conditional_edges( # First, we define the start node. We use 'agent'. # This means these are the edges taken after the 'agent' node is called.\n",
    "    \"agent\", # Next, we pass in the function that will determine which node is called next.\n",
    "    should_continue,\n",
    ")\n",
    "\n",
    "# We now add a normal edge from 'tools' to 'agent'.\n",
    "# This means that after 'tools' is called, 'agent' node is called next.\n",
    "workflow.add_edge(\"tools\", 'agent')\n",
    "\n",
    "# Finally, we compile it!\n",
    "# This compiles it into a LangChain Runnable,\n",
    "# meaning you can use it as you would any other runnable.\n",
    "# Note that we're (optionally) passing the memory when compiling the graph\n",
    "app = workflow.compile()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "24f21f81",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Client.create_dataset() got an unexpected keyword argument 'inputs'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[103]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m      7\u001b[39m answers = [    \u001b[33m\"\u001b[39m\u001b[33mIt\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms 60 degrees and foggy.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      8\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mIt\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms 60 degrees and foggy.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      9\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mIt\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms 90 degrees and sunny.\u001b[39m\u001b[33m\"\u001b[39m,]\n\u001b[32m     11\u001b[39m ls_client = Client()\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m dataset = \u001b[43mls_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweather agent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m                                   \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquestion\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mquestions\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m                                   \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43manswer\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43manswers\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: Client.create_dataset() got an unexpected keyword argument 'inputs'"
     ]
    }
   ],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "questions = [    \"what's the weather in sf\",\n",
    "    \"whats the weather in san fran\",\n",
    "    \"whats the weather in tangier\"]\n",
    "\n",
    "answers = [    \"It's 60 degrees and foggy.\",\n",
    "    \"It's 60 degrees and foggy.\",\n",
    "    \"It's 90 degrees and sunny.\",]\n",
    "\n",
    "ls_client = Client()\n",
    "\n",
    "dataset = ls_client.create_dataset(\"weather agent\", \n",
    "                                   inputs=[{\"question\": q} for q in questions],\n",
    "                                   outputs=[{\"answer\": a} for a in answers])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592fb11b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'example_ids': ['a8d34472-29dd-4321-9c50-42a8c2f97889',\n",
       "  'b90d4ebf-2758-47e6-9e74-76fd21d75593',\n",
       "  '2a8b6409-8021-4302-85e9-b23d5f2be751',\n",
       "  '594388d4-dc04-4430-9338-dca501b4fbb9',\n",
       "  '29aa796d-1631-45f1-be54-264e395cc0b9'],\n",
       " 'count': 5}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fixed Dataset\n",
    "# Golden Dataset\n",
    "# Metrics Performance\n",
    "# Run Evals - Different Prompts/Models - Different from the golden set which is inputs/outputs\n",
    "# Compare manually results\n",
    "# Track results over time\n",
    "# Automated Testing to run in CI/CD\n",
    "# Eval Workflows - Langsmith\n",
    "# Eval Model\n",
    "# Datapoints:\n",
    "# 1. Schema - Input + Maybe Output: # Expected Docs/Context Steps for agent or output - perfect answer or not \n",
    "# 2. How much - Coverage Edge Cases Guard\n",
    "# 3. How gather - grow eover time - pain ponitns - synthetic - hand labelling\n",
    "\n",
    "# evaluating what s expected in abstracted wasys\n",
    "\n",
    "# test cases vs eval metrics\n",
    "\n",
    "from langsmith import Client\n",
    "client = Client()\n",
    "\n",
    "dataset_name = \"QA Example Dataset\"\n",
    "dataset = client.create_dataset(dataset_name)\n",
    "# cloud eval platform but with less features\n",
    "\n",
    "client.create_examples(dataset_id=dataset.id,\n",
    "                       examples=[\n",
    "                           {\n",
    "            \"inputs\": {\"question\": \"What is LangChain?\"},\n",
    "            \"outputs\": {\"answer\": \"A framework for building LLM applications\"},\n",
    "        },\n",
    "        {\n",
    "            \"inputs\": {\"question\": \"What is LangSmith?\"},\n",
    "            \"outputs\": {\"answer\": \"A platform for observing and evaluating LLM applications\"},\n",
    "        },\n",
    "        {\n",
    "            \"inputs\": {\"question\": \"What is OpenAI?\"},\n",
    "            \"outputs\": {\"answer\": \"A company that creates Large Language Models\"},\n",
    "        },\n",
    "        {\n",
    "            \"inputs\": {\"question\": \"What is Google?\"},\n",
    "            \"outputs\": {\"answer\": \"A technology company known for search\"},\n",
    "        },\n",
    "        {\n",
    "            \"inputs\": {\"question\": \"What is Mistral?\"},\n",
    "            \"outputs\": {\"answer\": \"A company that creates Large Language Models\"},\n",
    "        }\n",
    "                       ])\n",
    "\n",
    "# Rubric schema\n",
    "# eeven for strucutred outptu \n",
    "# some initial runs then eval piepeline \n",
    "# engineer must know tewstin gand eval \n",
    "# eval is for a model over a set of inputs outputs - known and unknow n cases - this is for an app\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "72deecff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/openai-cookbook/examples/object_oriented_agentic_approach/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'openai-4o-mini-3dc20335' at:\n",
      "https://smith.langchain.com/o/a5a84604-398b-52cb-a407-151c2db4c0f2/datasets/de07d102-793b-425b-a4f0-588f17de145f/compare?selectedSessions=33a58916-9fe3-411e-907e-3d66c1e86628\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is OpenAI?\",\n",
      "  \"response\": \"OpenAI is an artificial intelligence research organization focused on developing and promoting friendly AI.\",\n",
      "  \"answer\": \"A company that creates Large Language Models\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is OpenAI?\",\n",
      "  \"response\": \"OpenAI is an artificial intelligence research organization focused on developing and promoting friendly AI.\",\n",
      "  \"answer\": \"A company that creates Large Language Models\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: You are an expert professor specialized in grading students' answers to questions.\\nHuman: You are grading the following question:\\n    What is OpenAI?\\n    Here is the real answer:\\n    A company that creates Large Language Models\\n    You are grading the following predicted answer:\\n    OpenAI is an artificial intelligence research organization focused on developing and promoting friendly AI.\"\n",
      "  ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] [1.16s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"grade\\\":\\\"CORRECT\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"grade\\\":\\\"CORRECT\\\"}\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"parsed\": {\n",
      "                \"lc\": 1,\n",
      "                \"type\": \"not_implemented\",\n",
      "                \"id\": [\n",
      "                  \"__main__\",\n",
      "                  \"CorrectnessEvaluator\"\n",
      "                ],\n",
      "                \"repr\": \"CorrectnessEvaluator(grade='CORRECT')\"\n",
      "              },\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 6,\n",
      "                \"prompt_tokens\": 161,\n",
      "                \"total_tokens\": 167,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "              \"system_fingerprint\": \"fp_34a54ae93c\",\n",
      "              \"id\": \"chatcmpl-Bcs7kYqdkS32fwmHlufQnvkdEbrah\",\n",
      "              \"service_tier\": \"default\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run--093309e7-1de3-4870-bdc9-8487e1099574-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 161,\n",
      "              \"output_tokens\": 6,\n",
      "              \"total_tokens\": 167,\n",
      "              \"input_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"cache_read\": 0\n",
      "              },\n",
      "              \"output_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"reasoning\": 0\n",
      "              }\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 6,\n",
      "      \"prompt_tokens\": 161,\n",
      "      \"total_tokens\": 167,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "    \"system_fingerprint\": \"fp_34a54ae93c\",\n",
      "    \"id\": \"chatcmpl-Bcs7kYqdkS32fwmHlufQnvkdEbrah\",\n",
      "    \"service_tier\": \"default\"\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableLambda] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [1.17s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is LangChain?\",\n",
      "  \"response\": \"LangChain is a framework for developing applications powered by language models.\",\n",
      "  \"answer\": \"A framework for building LLM applications\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is LangChain?\",\n",
      "  \"response\": \"LangChain is a framework for developing applications powered by language models.\",\n",
      "  \"answer\": \"A framework for building LLM applications\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: You are an expert professor specialized in grading students' answers to questions.\\nHuman: You are grading the following question:\\n    What is LangChain?\\n    Here is the real answer:\\n    A framework for building LLM applications\\n    You are grading the following predicted answer:\\n    LangChain is a framework for developing applications powered by language models.\"\n",
      "  ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:03,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] [840ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"grade\\\":\\\"CORRECT\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"grade\\\":\\\"CORRECT\\\"}\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"parsed\": {\n",
      "                \"lc\": 1,\n",
      "                \"type\": \"not_implemented\",\n",
      "                \"id\": [\n",
      "                  \"__main__\",\n",
      "                  \"CorrectnessEvaluator\"\n",
      "                ],\n",
      "                \"repr\": \"CorrectnessEvaluator(grade='CORRECT')\"\n",
      "              },\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 6,\n",
      "                \"prompt_tokens\": 158,\n",
      "                \"total_tokens\": 164,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "              \"system_fingerprint\": \"fp_34a54ae93c\",\n",
      "              \"id\": \"chatcmpl-Bcs7mceyfJCENJcE6mwrf7fLZDTkm\",\n",
      "              \"service_tier\": \"default\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run--e4fe4b8f-0194-4c33-8714-25f69aa4ae83-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 158,\n",
      "              \"output_tokens\": 6,\n",
      "              \"total_tokens\": 164,\n",
      "              \"input_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"cache_read\": 0\n",
      "              },\n",
      "              \"output_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"reasoning\": 0\n",
      "              }\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 6,\n",
      "      \"prompt_tokens\": 158,\n",
      "      \"total_tokens\": 164,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "    \"system_fingerprint\": \"fp_34a54ae93c\",\n",
      "    \"id\": \"chatcmpl-Bcs7mceyfJCENJcE6mwrf7fLZDTkm\",\n",
      "    \"service_tier\": \"default\"\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableLambda] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [848ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is LangSmith?\",\n",
      "  \"response\": \"LangSmith is a platform designed for building and deploying language models.\",\n",
      "  \"answer\": \"A platform for observing and evaluating LLM applications\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is LangSmith?\",\n",
      "  \"response\": \"LangSmith is a platform designed for building and deploying language models.\",\n",
      "  \"answer\": \"A platform for observing and evaluating LLM applications\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: You are an expert professor specialized in grading students' answers to questions.\\nHuman: You are grading the following question:\\n    What is LangSmith?\\n    Here is the real answer:\\n    A platform for observing and evaluating LLM applications\\n    You are grading the following predicted answer:\\n    LangSmith is a platform designed for building and deploying language models.\"\n",
      "  ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:05,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] [975ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"grade\\\":\\\"INCORRECT\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"grade\\\":\\\"INCORRECT\\\"}\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"parsed\": {\n",
      "                \"lc\": 1,\n",
      "                \"type\": \"not_implemented\",\n",
      "                \"id\": [\n",
      "                  \"__main__\",\n",
      "                  \"CorrectnessEvaluator\"\n",
      "                ],\n",
      "                \"repr\": \"CorrectnessEvaluator(grade='INCORRECT')\"\n",
      "              },\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 7,\n",
      "                \"prompt_tokens\": 160,\n",
      "                \"total_tokens\": 167,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "              \"system_fingerprint\": \"fp_34a54ae93c\",\n",
      "              \"id\": \"chatcmpl-Bcs7ol8R5X686p5jYLZuGfo1oKMmn\",\n",
      "              \"service_tier\": \"default\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run--0c84c3db-7fcb-4cde-b85d-8689a1f2f00b-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 160,\n",
      "              \"output_tokens\": 7,\n",
      "              \"total_tokens\": 167,\n",
      "              \"input_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"cache_read\": 0\n",
      "              },\n",
      "              \"output_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"reasoning\": 0\n",
      "              }\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 7,\n",
      "      \"prompt_tokens\": 160,\n",
      "      \"total_tokens\": 167,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "    \"system_fingerprint\": \"fp_34a54ae93c\",\n",
      "    \"id\": \"chatcmpl-Bcs7ol8R5X686p5jYLZuGfo1oKMmn\",\n",
      "    \"service_tier\": \"default\"\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableLambda] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [982ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is Google?\",\n",
      "  \"response\": \"Google is a multinational technology company specializing in Internet-related services and products, including search engines, online advertising, and cloud computing.\",\n",
      "  \"answer\": \"A technology company known for search\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is Google?\",\n",
      "  \"response\": \"Google is a multinational technology company specializing in Internet-related services and products, including search engines, online advertising, and cloud computing.\",\n",
      "  \"answer\": \"A technology company known for search\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: You are an expert professor specialized in grading students' answers to questions.\\nHuman: You are grading the following question:\\n    What is Google?\\n    Here is the real answer:\\n    A technology company known for search\\n    You are grading the following predicted answer:\\n    Google is a multinational technology company specializing in Internet-related services and products, including search engines, online advertising, and cloud computing.\"\n",
      "  ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:06,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] [395ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"grade\\\":\\\"CORRECT\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"grade\\\":\\\"CORRECT\\\"}\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"parsed\": {\n",
      "                \"lc\": 1,\n",
      "                \"type\": \"not_implemented\",\n",
      "                \"id\": [\n",
      "                  \"__main__\",\n",
      "                  \"CorrectnessEvaluator\"\n",
      "                ],\n",
      "                \"repr\": \"CorrectnessEvaluator(grade='CORRECT')\"\n",
      "              },\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 6,\n",
      "                \"prompt_tokens\": 168,\n",
      "                \"total_tokens\": 174,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "              \"system_fingerprint\": \"fp_34a54ae93c\",\n",
      "              \"id\": \"chatcmpl-Bcs7pbqO9m8f9uDgTKDdIDhXdc8hp\",\n",
      "              \"service_tier\": \"default\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run--cae3fb13-3cc4-494a-ac82-13949174ce7f-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 168,\n",
      "              \"output_tokens\": 6,\n",
      "              \"total_tokens\": 174,\n",
      "              \"input_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"cache_read\": 0\n",
      "              },\n",
      "              \"output_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"reasoning\": 0\n",
      "              }\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 6,\n",
      "      \"prompt_tokens\": 168,\n",
      "      \"total_tokens\": 174,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "    \"system_fingerprint\": \"fp_34a54ae93c\",\n",
      "    \"id\": \"chatcmpl-Bcs7pbqO9m8f9uDgTKDdIDhXdc8hp\",\n",
      "    \"service_tier\": \"default\"\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableLambda] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [401ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is Mistral?\",\n",
      "  \"response\": \"Mistral is a type of wind that occurs in southern France, characterized by its strong, cold, and dry nature.\",\n",
      "  \"answer\": \"A company that creates Large Language Models\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is Mistral?\",\n",
      "  \"response\": \"Mistral is a type of wind that occurs in southern France, characterized by its strong, cold, and dry nature.\",\n",
      "  \"answer\": \"A company that creates Large Language Models\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: You are an expert professor specialized in grading students' answers to questions.\\nHuman: You are grading the following question:\\n    What is Mistral?\\n    Here is the real answer:\\n    A company that creates Large Language Models\\n    You are grading the following predicted answer:\\n    Mistral is a type of wind that occurs in southern France, characterized by its strong, cold, and dry nature.\"\n",
      "  ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:08,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] [832ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"grade\\\":\\\"INCORRECT\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"grade\\\":\\\"INCORRECT\\\"}\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"parsed\": {\n",
      "                \"lc\": 1,\n",
      "                \"type\": \"not_implemented\",\n",
      "                \"id\": [\n",
      "                  \"__main__\",\n",
      "                  \"CorrectnessEvaluator\"\n",
      "                ],\n",
      "                \"repr\": \"CorrectnessEvaluator(grade='INCORRECT')\"\n",
      "              },\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 7,\n",
      "                \"prompt_tokens\": 171,\n",
      "                \"total_tokens\": 178,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "              \"system_fingerprint\": \"fp_34a54ae93c\",\n",
      "              \"id\": \"chatcmpl-Bcs7qMz3abX2n1WNbdzgS7G0HmuGp\",\n",
      "              \"service_tier\": \"default\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run--be81c83d-c4f1-4ca3-9289-34c3eaa431bb-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 171,\n",
      "              \"output_tokens\": 7,\n",
      "              \"total_tokens\": 178,\n",
      "              \"input_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"cache_read\": 0\n",
      "              },\n",
      "              \"output_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"reasoning\": 0\n",
      "              }\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 7,\n",
      "      \"prompt_tokens\": 171,\n",
      "      \"total_tokens\": 178,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "    \"system_fingerprint\": \"fp_34a54ae93c\",\n",
      "    \"id\": \"chatcmpl-Bcs7qMz3abX2n1WNbdzgS7G0HmuGp\",\n",
      "    \"service_tier\": \"default\"\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableLambda] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [840ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:08,  1.67s/it]\n"
     ]
    }
   ],
   "source": [
    "# type of metric requires deterministic or non deterministic evaluation in terms of measure in perfection \n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "import openai\n",
    "from langsmith import wrappers\n",
    "from pydantic import BaseModel, Field\n",
    "from sqlalchemy import desc\n",
    "\n",
    "# eval onm prolmtp sor models\n",
    "\n",
    "openai_client = openai.OpenAI()\n",
    "\n",
    "eval_instructions = \"You are an expert professor specialized in grading students' answers to questions.\"\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.0)\n",
    "\n",
    "class CorrectnessEvaluator(BaseModel):\n",
    "    \"\"\"Use this schema to structure your grading of student answers.\"\"\"\n",
    "    grade: Literal[\"CORRECT\", \"INCORRECT\"] = Field(description=\"The grade of the answer, either 'CORRECT' or 'INCORRECT'.\")\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "def correctness(inputs: dict, outputs: dict, reference_outputs: dict) -> bool:\n",
    "    llm_with_structured_output = llm.with_structured_output(CorrectnessEvaluator)\n",
    "    prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", eval_instructions),    \n",
    "    (\"human\", \"\"\"You are grading the following question:\n",
    "    {question}\n",
    "    Here is the real answer:\n",
    "    {answer}\n",
    "    You are grading the following predicted answer:\n",
    "    {response}\"\"\")])\n",
    "\n",
    "    correctness_runnable = prompt_template | llm_with_structured_output\n",
    "\n",
    "    correctness_evaluator = correctness_runnable.invoke(\n",
    "        {\"question\": inputs[\"question\"], \"response\": outputs[\"response\"], \"answer\": reference_outputs[\"answer\"]})\n",
    "    \n",
    "    return correctness_evaluator.grade == \"CORRECT\"\n",
    "\n",
    "# built in ones as well \n",
    "\n",
    "# evalaution resutl scoudl be classifiecation type as well\n",
    "# not just binary - multi calss - so usually llm suffices this as a zero shto thign\n",
    "\n",
    "def concision(outputs: dict, reference_outputs: dict) -> bool:\n",
    "    return bool(int(len(outputs[\"response\"]) < 2 * len(reference_outputs[\"answer\"])))\n",
    "\n",
    "# Test driven development\n",
    "default_instructions = \"Respond to the users question in a short, concise manner (one short sentence).\"\n",
    "\n",
    "def my_app(question: str, model: str = \"gpt-4o-mini\", instructions: str = default_instructions) -> str:\n",
    "    return openai_client.chat.completions.create(\n",
    "        model=model,\n",
    "        temperature=0,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": instructions},\n",
    "            {\"role\": \"user\", \"content\": question},\n",
    "        ],\n",
    "    ).choices[0].message.content\n",
    "\n",
    "# Test all aspects of our promtp etc \n",
    "\n",
    "def ls_target(inputs: str) -> dict:\n",
    "    \"\"\"The target function for LangSmith.\"\"\"\n",
    "    return {\"response\": my_app(inputs[\"question\"])}\n",
    "\n",
    "# We call this an experiemtn\n",
    "# a promtp a dataset \n",
    "# human and metric evlaaution\n",
    "\n",
    "experiment_results = client.evaluate(\n",
    "    ls_target,\n",
    "    data=dataset_name,\n",
    "    evaluators=[correctness, concision], #metrics to score\n",
    "    experiment_prefix=\"openai-4o-mini\"\n",
    ")\n",
    "\n",
    "# model evaluatiosn not promtp iterations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5945455e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'openai-4-turbo-c461d936' at:\n",
      "https://smith.langchain.com/o/a5a84604-398b-52cb-a407-151c2db4c0f2/datasets/de07d102-793b-425b-a4f0-588f17de145f/compare?selectedSessions=449028e6-7b54-4f15-ad21-57660e592161\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is OpenAI?\",\n",
      "  \"response\": \"OpenAI is an artificial intelligence research lab that focuses on developing and promoting friendly AI in a way that benefits humanity as a whole.\",\n",
      "  \"answer\": \"A company that creates Large Language Models\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is OpenAI?\",\n",
      "  \"response\": \"OpenAI is an artificial intelligence research lab that focuses on developing and promoting friendly AI in a way that benefits humanity as a whole.\",\n",
      "  \"answer\": \"A company that creates Large Language Models\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: You are an expert professor specialized in grading students' answers to questions.\\nHuman: You are grading the following question:\\n    What is OpenAI?\\n    Here is the real answer:\\n    A company that creates Large Language Models\\n    You are grading the following predicted answer:\\n    OpenAI is an artificial intelligence research lab that focuses on developing and promoting friendly AI in a way that benefits humanity as a whole.\"\n",
      "  ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] [574ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"grade\\\":\\\"CORRECT\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"grade\\\":\\\"CORRECT\\\"}\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"parsed\": {\n",
      "                \"lc\": 1,\n",
      "                \"type\": \"not_implemented\",\n",
      "                \"id\": [\n",
      "                  \"__main__\",\n",
      "                  \"CorrectnessEvaluator\"\n",
      "                ],\n",
      "                \"repr\": \"CorrectnessEvaluator(grade='CORRECT')\"\n",
      "              },\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 6,\n",
      "                \"prompt_tokens\": 171,\n",
      "                \"total_tokens\": 177,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "              \"system_fingerprint\": \"fp_34a54ae93c\",\n",
      "              \"id\": \"chatcmpl-BcsEA6Fl7wmx2V8hHixmepJuubXm9\",\n",
      "              \"service_tier\": \"default\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run--9e47fa50-0c92-4f9a-81b1-71e4dac11cc6-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 171,\n",
      "              \"output_tokens\": 6,\n",
      "              \"total_tokens\": 177,\n",
      "              \"input_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"cache_read\": 0\n",
      "              },\n",
      "              \"output_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"reasoning\": 0\n",
      "              }\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 6,\n",
      "      \"prompt_tokens\": 171,\n",
      "      \"total_tokens\": 177,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "    \"system_fingerprint\": \"fp_34a54ae93c\",\n",
      "    \"id\": \"chatcmpl-BcsEA6Fl7wmx2V8hHixmepJuubXm9\",\n",
      "    \"service_tier\": \"default\"\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableLambda] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [582ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is LangChain?\",\n",
      "  \"response\": \"LangChain is a framework designed to facilitate the development of applications that integrate language models like ChatGPT with external tools and data sources.\",\n",
      "  \"answer\": \"A framework for building LLM applications\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is LangChain?\",\n",
      "  \"response\": \"LangChain is a framework designed to facilitate the development of applications that integrate language models like ChatGPT with external tools and data sources.\",\n",
      "  \"answer\": \"A framework for building LLM applications\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: You are an expert professor specialized in grading students' answers to questions.\\nHuman: You are grading the following question:\\n    What is LangChain?\\n    Here is the real answer:\\n    A framework for building LLM applications\\n    You are grading the following predicted answer:\\n    LangChain is a framework designed to facilitate the development of applications that integrate language models like ChatGPT with external tools and data sources.\"\n",
      "  ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:03,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] [456ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"grade\\\":\\\"CORRECT\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"grade\\\":\\\"CORRECT\\\"}\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"parsed\": {\n",
      "                \"lc\": 1,\n",
      "                \"type\": \"not_implemented\",\n",
      "                \"id\": [\n",
      "                  \"__main__\",\n",
      "                  \"CorrectnessEvaluator\"\n",
      "                ],\n",
      "                \"repr\": \"CorrectnessEvaluator(grade='CORRECT')\"\n",
      "              },\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 6,\n",
      "                \"prompt_tokens\": 171,\n",
      "                \"total_tokens\": 177,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "              \"system_fingerprint\": \"fp_34a54ae93c\",\n",
      "              \"id\": \"chatcmpl-BcsEC3jHW0BGDnKfYLsl0z4j4P1io\",\n",
      "              \"service_tier\": \"default\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run--1d43a68e-d0cc-4374-a177-e2469c07d69e-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 171,\n",
      "              \"output_tokens\": 6,\n",
      "              \"total_tokens\": 177,\n",
      "              \"input_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"cache_read\": 0\n",
      "              },\n",
      "              \"output_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"reasoning\": 0\n",
      "              }\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 6,\n",
      "      \"prompt_tokens\": 171,\n",
      "      \"total_tokens\": 177,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "    \"system_fingerprint\": \"fp_34a54ae93c\",\n",
      "    \"id\": \"chatcmpl-BcsEC3jHW0BGDnKfYLsl0z4j4P1io\",\n",
      "    \"service_tier\": \"default\"\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableLambda] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [463ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is LangSmith?\",\n",
      "  \"response\": \"LangSmith is a language learning platform that uses AI to help users improve their writing skills in English.\",\n",
      "  \"answer\": \"A platform for observing and evaluating LLM applications\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is LangSmith?\",\n",
      "  \"response\": \"LangSmith is a language learning platform that uses AI to help users improve their writing skills in English.\",\n",
      "  \"answer\": \"A platform for observing and evaluating LLM applications\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: You are an expert professor specialized in grading students' answers to questions.\\nHuman: You are grading the following question:\\n    What is LangSmith?\\n    Here is the real answer:\\n    A platform for observing and evaluating LLM applications\\n    You are grading the following predicted answer:\\n    LangSmith is a language learning platform that uses AI to help users improve their writing skills in English.\"\n",
      "  ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:05,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] [709ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"grade\\\":\\\"INCORRECT\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"grade\\\":\\\"INCORRECT\\\"}\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"parsed\": {\n",
      "                \"lc\": 1,\n",
      "                \"type\": \"not_implemented\",\n",
      "                \"id\": [\n",
      "                  \"__main__\",\n",
      "                  \"CorrectnessEvaluator\"\n",
      "                ],\n",
      "                \"repr\": \"CorrectnessEvaluator(grade='INCORRECT')\"\n",
      "              },\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 7,\n",
      "                \"prompt_tokens\": 167,\n",
      "                \"total_tokens\": 174,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "              \"system_fingerprint\": \"fp_34a54ae93c\",\n",
      "              \"id\": \"chatcmpl-BcsEEjMQCF5CkcF2xrRo4RDVAG4OK\",\n",
      "              \"service_tier\": \"default\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run--91f7392c-f19d-4f5b-a736-3b3db2c8d677-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 167,\n",
      "              \"output_tokens\": 7,\n",
      "              \"total_tokens\": 174,\n",
      "              \"input_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"cache_read\": 0\n",
      "              },\n",
      "              \"output_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"reasoning\": 0\n",
      "              }\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 7,\n",
      "      \"prompt_tokens\": 167,\n",
      "      \"total_tokens\": 174,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "    \"system_fingerprint\": \"fp_34a54ae93c\",\n",
      "    \"id\": \"chatcmpl-BcsEEjMQCF5CkcF2xrRo4RDVAG4OK\",\n",
      "    \"service_tier\": \"default\"\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableLambda] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [717ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is Google?\",\n",
      "  \"response\": \"Google is a multinational technology company specializing in internet-related services and products, including search engines, online advertising, and cloud computing.\",\n",
      "  \"answer\": \"A technology company known for search\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is Google?\",\n",
      "  \"response\": \"Google is a multinational technology company specializing in internet-related services and products, including search engines, online advertising, and cloud computing.\",\n",
      "  \"answer\": \"A technology company known for search\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: You are an expert professor specialized in grading students' answers to questions.\\nHuman: You are grading the following question:\\n    What is Google?\\n    Here is the real answer:\\n    A technology company known for search\\n    You are grading the following predicted answer:\\n    Google is a multinational technology company specializing in internet-related services and products, including search engines, online advertising, and cloud computing.\"\n",
      "  ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:07,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] [1.54s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"grade\\\":\\\"CORRECT\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"grade\\\":\\\"CORRECT\\\"}\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"parsed\": {\n",
      "                \"lc\": 1,\n",
      "                \"type\": \"not_implemented\",\n",
      "                \"id\": [\n",
      "                  \"__main__\",\n",
      "                  \"CorrectnessEvaluator\"\n",
      "                ],\n",
      "                \"repr\": \"CorrectnessEvaluator(grade='CORRECT')\"\n",
      "              },\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 6,\n",
      "                \"prompt_tokens\": 168,\n",
      "                \"total_tokens\": 174,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "              \"system_fingerprint\": \"fp_34a54ae93c\",\n",
      "              \"id\": \"chatcmpl-BcsEG6OfUluUTWMODspIOARmoHoQt\",\n",
      "              \"service_tier\": \"default\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run--bac37e48-cc00-4bcd-8a3d-8f9a0c80e400-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 168,\n",
      "              \"output_tokens\": 6,\n",
      "              \"total_tokens\": 174,\n",
      "              \"input_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"cache_read\": 0\n",
      "              },\n",
      "              \"output_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"reasoning\": 0\n",
      "              }\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 6,\n",
      "      \"prompt_tokens\": 168,\n",
      "      \"total_tokens\": 174,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "    \"system_fingerprint\": \"fp_34a54ae93c\",\n",
      "    \"id\": \"chatcmpl-BcsEG6OfUluUTWMODspIOARmoHoQt\",\n",
      "    \"service_tier\": \"default\"\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableLambda] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [1.55s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is Mistral?\",\n",
      "  \"response\": \"Mistral is a strong, cold, northwesterly wind that blows from southern France into the Mediterranean, primarily in winter.\",\n",
      "  \"answer\": \"A company that creates Large Language Models\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is Mistral?\",\n",
      "  \"response\": \"Mistral is a strong, cold, northwesterly wind that blows from southern France into the Mediterranean, primarily in winter.\",\n",
      "  \"answer\": \"A company that creates Large Language Models\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: You are an expert professor specialized in grading students' answers to questions.\\nHuman: You are grading the following question:\\n    What is Mistral?\\n    Here is the real answer:\\n    A company that creates Large Language Models\\n    You are grading the following predicted answer:\\n    Mistral is a strong, cold, northwesterly wind that blows from southern France into the Mediterranean, primarily in winter.\"\n",
      "  ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:09,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] [495ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"grade\\\":\\\"INCORRECT\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"grade\\\":\\\"INCORRECT\\\"}\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"parsed\": {\n",
      "                \"lc\": 1,\n",
      "                \"type\": \"not_implemented\",\n",
      "                \"id\": [\n",
      "                  \"__main__\",\n",
      "                  \"CorrectnessEvaluator\"\n",
      "                ],\n",
      "                \"repr\": \"CorrectnessEvaluator(grade='INCORRECT')\"\n",
      "              },\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 7,\n",
      "                \"prompt_tokens\": 173,\n",
      "                \"total_tokens\": 180,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "              \"system_fingerprint\": \"fp_34a54ae93c\",\n",
      "              \"id\": \"chatcmpl-BcsEII73v8bH8TLFh3qLFUUw0bDcu\",\n",
      "              \"service_tier\": \"default\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run--f01bb643-a04c-4472-ab26-1019add8ce98-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 173,\n",
      "              \"output_tokens\": 7,\n",
      "              \"total_tokens\": 180,\n",
      "              \"input_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"cache_read\": 0\n",
      "              },\n",
      "              \"output_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"reasoning\": 0\n",
      "              }\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 7,\n",
      "      \"prompt_tokens\": 173,\n",
      "      \"total_tokens\": 180,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "    \"system_fingerprint\": \"fp_34a54ae93c\",\n",
      "    \"id\": \"chatcmpl-BcsEII73v8bH8TLFh3qLFUUw0bDcu\",\n",
      "    \"service_tier\": \"default\"\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableLambda] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [502ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:09,  1.93s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def ls_target_v2(inputs: str) -> dict:\n",
    "    return {\"response\": my_app(inputs[\"question\"], model=\"gpt-4-turbo\")}\n",
    "\n",
    "experiment_results = client.evaluate(\n",
    "    ls_target_v2,\n",
    "    data=dataset_name,\n",
    "    evaluators=[concision, correctness],\n",
    "    experiment_prefix=\"openai-4-turbo\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a8512586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'strict-openai-4-turbo-b2260485' at:\n",
      "https://smith.langchain.com/o/a5a84604-398b-52cb-a407-151c2db4c0f2/datasets/de07d102-793b-425b-a4f0-588f17de145f/compare?selectedSessions=0413ee9a-3086-4925-8a81-a77a0aadf022\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is OpenAI?\",\n",
      "  \"response\": \"OpenAI is an AI research and deployment company.\",\n",
      "  \"answer\": \"A company that creates Large Language Models\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is OpenAI?\",\n",
      "  \"response\": \"OpenAI is an AI research and deployment company.\",\n",
      "  \"answer\": \"A company that creates Large Language Models\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: You are an expert professor specialized in grading students' answers to questions.\\nHuman: You are grading the following question:\\n    What is OpenAI?\\n    Here is the real answer:\\n    A company that creates Large Language Models\\n    You are grading the following predicted answer:\\n    OpenAI is an AI research and deployment company.\"\n",
      "  ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:02,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] [880ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"grade\\\":\\\"CORRECT\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"grade\\\":\\\"CORRECT\\\"}\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"parsed\": {\n",
      "                \"lc\": 1,\n",
      "                \"type\": \"not_implemented\",\n",
      "                \"id\": [\n",
      "                  \"__main__\",\n",
      "                  \"CorrectnessEvaluator\"\n",
      "                ],\n",
      "                \"repr\": \"CorrectnessEvaluator(grade='CORRECT')\"\n",
      "              },\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 6,\n",
      "                \"prompt_tokens\": 155,\n",
      "                \"total_tokens\": 161,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "              \"system_fingerprint\": \"fp_34a54ae93c\",\n",
      "              \"id\": \"chatcmpl-BctJIuhP5ZSIoBrHDEVNl1DhAHEiL\",\n",
      "              \"service_tier\": \"default\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run--39f4d3c1-1986-4f60-b657-da934ff85354-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 155,\n",
      "              \"output_tokens\": 6,\n",
      "              \"total_tokens\": 161,\n",
      "              \"input_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"cache_read\": 0\n",
      "              },\n",
      "              \"output_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"reasoning\": 0\n",
      "              }\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 6,\n",
      "      \"prompt_tokens\": 155,\n",
      "      \"total_tokens\": 161,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "    \"system_fingerprint\": \"fp_34a54ae93c\",\n",
      "    \"id\": \"chatcmpl-BctJIuhP5ZSIoBrHDEVNl1DhAHEiL\",\n",
      "    \"service_tier\": \"default\"\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableLambda] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [888ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is LangChain?\",\n",
      "  \"response\": \"LangChain is a toolkit for building language model-powered applications.\",\n",
      "  \"answer\": \"A framework for building LLM applications\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is LangChain?\",\n",
      "  \"response\": \"LangChain is a toolkit for building language model-powered applications.\",\n",
      "  \"answer\": \"A framework for building LLM applications\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: You are an expert professor specialized in grading students' answers to questions.\\nHuman: You are grading the following question:\\n    What is LangChain?\\n    Here is the real answer:\\n    A framework for building LLM applications\\n    You are grading the following predicted answer:\\n    LangChain is a toolkit for building language model-powered applications.\"\n",
      "  ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:05,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] [359ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"grade\\\":\\\"CORRECT\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"grade\\\":\\\"CORRECT\\\"}\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"parsed\": {\n",
      "                \"lc\": 1,\n",
      "                \"type\": \"not_implemented\",\n",
      "                \"id\": [\n",
      "                  \"__main__\",\n",
      "                  \"CorrectnessEvaluator\"\n",
      "                ],\n",
      "                \"repr\": \"CorrectnessEvaluator(grade='CORRECT')\"\n",
      "              },\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 6,\n",
      "                \"prompt_tokens\": 157,\n",
      "                \"total_tokens\": 163,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "              \"system_fingerprint\": \"fp_34a54ae93c\",\n",
      "              \"id\": \"chatcmpl-BctJL34JSkJsXqcmuEwdKEVOv6gIu\",\n",
      "              \"service_tier\": \"default\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run--9e30b590-e9aa-4552-b815-a5b5b35b6e05-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 157,\n",
      "              \"output_tokens\": 6,\n",
      "              \"total_tokens\": 163,\n",
      "              \"input_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"cache_read\": 0\n",
      "              },\n",
      "              \"output_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"reasoning\": 0\n",
      "              }\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 6,\n",
      "      \"prompt_tokens\": 157,\n",
      "      \"total_tokens\": 163,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "    \"system_fingerprint\": \"fp_34a54ae93c\",\n",
      "    \"id\": \"chatcmpl-BctJL34JSkJsXqcmuEwdKEVOv6gIu\",\n",
      "    \"service_tier\": \"default\"\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableLambda] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [366ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is LangSmith?\",\n",
      "  \"response\": \"LangSmith is an AI-powered writing and editing tool.\",\n",
      "  \"answer\": \"A platform for observing and evaluating LLM applications\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is LangSmith?\",\n",
      "  \"response\": \"LangSmith is an AI-powered writing and editing tool.\",\n",
      "  \"answer\": \"A platform for observing and evaluating LLM applications\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: You are an expert professor specialized in grading students' answers to questions.\\nHuman: You are grading the following question:\\n    What is LangSmith?\\n    Here is the real answer:\\n    A platform for observing and evaluating LLM applications\\n    You are grading the following predicted answer:\\n    LangSmith is an AI-powered writing and editing tool.\"\n",
      "  ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:06,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] [676ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"grade\\\":\\\"INCORRECT\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"grade\\\":\\\"INCORRECT\\\"}\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"parsed\": {\n",
      "                \"lc\": 1,\n",
      "                \"type\": \"not_implemented\",\n",
      "                \"id\": [\n",
      "                  \"__main__\",\n",
      "                  \"CorrectnessEvaluator\"\n",
      "                ],\n",
      "                \"repr\": \"CorrectnessEvaluator(grade='INCORRECT')\"\n",
      "              },\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 7,\n",
      "                \"prompt_tokens\": 158,\n",
      "                \"total_tokens\": 165,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "              \"system_fingerprint\": null,\n",
      "              \"id\": \"chatcmpl-BctJN6XRXL7GGSmnicYCddAufVhht\",\n",
      "              \"service_tier\": \"default\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run--f89c52eb-01e5-4214-809d-2e7e1dd6b216-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 158,\n",
      "              \"output_tokens\": 7,\n",
      "              \"total_tokens\": 165,\n",
      "              \"input_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"cache_read\": 0\n",
      "              },\n",
      "              \"output_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"reasoning\": 0\n",
      "              }\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 7,\n",
      "      \"prompt_tokens\": 158,\n",
      "      \"total_tokens\": 165,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "    \"system_fingerprint\": null,\n",
      "    \"id\": \"chatcmpl-BctJN6XRXL7GGSmnicYCddAufVhht\",\n",
      "    \"service_tier\": \"default\"\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableLambda] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [684ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is Google?\",\n",
      "  \"response\": \"Google is a multinational technology company specializing in internet services.\",\n",
      "  \"answer\": \"A technology company known for search\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is Google?\",\n",
      "  \"response\": \"Google is a multinational technology company specializing in internet services.\",\n",
      "  \"answer\": \"A technology company known for search\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: You are an expert professor specialized in grading students' answers to questions.\\nHuman: You are grading the following question:\\n    What is Google?\\n    Here is the real answer:\\n    A technology company known for search\\n    You are grading the following predicted answer:\\n    Google is a multinational technology company specializing in internet services.\"\n",
      "  ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:09,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] [2.64s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"grade\\\":\\\"CORRECT\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"grade\\\":\\\"CORRECT\\\"}\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"parsed\": {\n",
      "                \"lc\": 1,\n",
      "                \"type\": \"not_implemented\",\n",
      "                \"id\": [\n",
      "                  \"__main__\",\n",
      "                  \"CorrectnessEvaluator\"\n",
      "                ],\n",
      "                \"repr\": \"CorrectnessEvaluator(grade='CORRECT')\"\n",
      "              },\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 6,\n",
      "                \"prompt_tokens\": 154,\n",
      "                \"total_tokens\": 160,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "              \"system_fingerprint\": \"fp_34a54ae93c\",\n",
      "              \"id\": \"chatcmpl-BctJQIq58IloQHXq0xW5aK4PxLwzg\",\n",
      "              \"service_tier\": \"default\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run--d2110960-5057-4662-9292-fb95d626417d-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 154,\n",
      "              \"output_tokens\": 6,\n",
      "              \"total_tokens\": 160,\n",
      "              \"input_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"cache_read\": 0\n",
      "              },\n",
      "              \"output_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"reasoning\": 0\n",
      "              }\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 6,\n",
      "      \"prompt_tokens\": 154,\n",
      "      \"total_tokens\": 160,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "    \"system_fingerprint\": \"fp_34a54ae93c\",\n",
      "    \"id\": \"chatcmpl-BctJQIq58IloQHXq0xW5aK4PxLwzg\",\n",
      "    \"service_tier\": \"default\"\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableLambda] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [2.64s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is Mistral?\",\n",
      "  \"response\": \"Mistral is a strong, cold wind in southern France.\",\n",
      "  \"answer\": \"A company that creates Large Language Models\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is Mistral?\",\n",
      "  \"response\": \"Mistral is a strong, cold wind in southern France.\",\n",
      "  \"answer\": \"A company that creates Large Language Models\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: You are an expert professor specialized in grading students' answers to questions.\\nHuman: You are grading the following question:\\n    What is Mistral?\\n    Here is the real answer:\\n    A company that creates Large Language Models\\n    You are grading the following predicted answer:\\n    Mistral is a strong, cold wind in southern France.\"\n",
      "  ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:11,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] [618ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"grade\\\":\\\"INCORRECT\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"grade\\\":\\\"INCORRECT\\\"}\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"parsed\": {\n",
      "                \"lc\": 1,\n",
      "                \"type\": \"not_implemented\",\n",
      "                \"id\": [\n",
      "                  \"__main__\",\n",
      "                  \"CorrectnessEvaluator\"\n",
      "                ],\n",
      "                \"repr\": \"CorrectnessEvaluator(grade='INCORRECT')\"\n",
      "              },\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 7,\n",
      "                \"prompt_tokens\": 159,\n",
      "                \"total_tokens\": 166,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "              \"system_fingerprint\": \"fp_34a54ae93c\",\n",
      "              \"id\": \"chatcmpl-BctJRnGXKw1f5wUvlQnDmHLGsfApq\",\n",
      "              \"service_tier\": \"default\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run--9bb3e20f-f22d-4915-ac5d-aeee21719ead-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 159,\n",
      "              \"output_tokens\": 7,\n",
      "              \"total_tokens\": 166,\n",
      "              \"input_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"cache_read\": 0\n",
      "              },\n",
      "              \"output_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"reasoning\": 0\n",
      "              }\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 7,\n",
      "      \"prompt_tokens\": 159,\n",
      "      \"total_tokens\": 166,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "    \"system_fingerprint\": \"fp_34a54ae93c\",\n",
      "    \"id\": \"chatcmpl-BctJRnGXKw1f5wUvlQnDmHLGsfApq\",\n",
      "    \"service_tier\": \"default\"\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableLambda] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [626ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:11,  2.31s/it]\n"
     ]
    }
   ],
   "source": [
    "instructions_v3 = \"Respond to the users question in a short, concise manner (one short sentence). Do NOT use more than ten words.\"\n",
    "\n",
    "def ls_target_v3(inputs: str) -> dict:\n",
    "    response = my_app(\n",
    "        inputs[\"question\"], \n",
    "        model=\"gpt-4-turbo\",\n",
    "        instructions=instructions_v3\n",
    "    )\n",
    "    return {\"response\": response}\n",
    "\n",
    "# experiemtn is linked to a datset - wehre you change the parameters of the models used and the features or promtps\n",
    "# baseline\n",
    "# very importnat to iterate like this - baseline run for a n expeirment and for a a metric\n",
    "# can be xacross experiements\n",
    "# chanign the input outpuit format means its a differnt experment and not comaprabel anymroe to the any behcmark sets as well\n",
    "\n",
    "\n",
    "experiment_results = client.evaluate(\n",
    "    ls_target_v3,\n",
    "    data=dataset_name,\n",
    "    evaluators=[concision, correctness],\n",
    "    experiment_prefix=\"strict-openai-4-turbo\",\n",
    ")\n",
    "\n",
    "# lookign for improvements aor regressions\n",
    "# 3 MANUAL COMAPRISON\n",
    "\n",
    "# CRITERAI OF PASS FROM THE RESUTLS from a baseline\n",
    "# over an experiemtn - over a datset not jsut one - many runs - could even do repateabilty fi temrparture is chanign\n",
    "\n",
    "# test is what says if we pass or not criterai\n",
    "\n",
    "# evalautors - human or metric based - they are able to let you score to create test cases \n",
    "\n",
    "# for non llm apps its not a meteric its a simple eval often so thats why its easier\n",
    "# edge cases etc coverage\n",
    "# coverage of edge cases vs if criteiria passes\n",
    "# tests are asserts - in programming can assert weach outptu \n",
    "# hear edo it over larger numebr?\n",
    "# test team shoudl set this up \n",
    "# only for dev team for test driven dev unti test ans dudnerstanding \n",
    "\n",
    "# to even design my own should know what comomon framowrks have \n",
    "# sairam\n",
    "# to make nintex specific\n",
    "# sairam\n",
    "\n",
    "def test_length_score() -> None:\n",
    "    \"Test that the length of the score is at least 80%\"\n",
    "    experiment_results = client.evaluate(ls_target, data=dataset_name, evaluators=[concision, correctness])\n",
    "    scores = [result.score for result in experiment_results.results]\n",
    "    assert sum(scores) / len(scores) >= 0.8, \"The average score is less than 80%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "da83107b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'kind-number-27' at:\n",
      "https://smith.langchain.com/o/a5a84604-398b-52cb-a407-151c2db4c0f2/datasets/de07d102-793b-425b-a4f0-588f17de145f/compare?selectedSessions=1a4f6a62-01f9-44dc-9bb0-cd604abd37dc\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is OpenAI?\",\n",
      "  \"response\": \"OpenAI is an artificial intelligence research organization focused on developing and promoting friendly AI.\",\n",
      "  \"answer\": \"A company that creates Large Language Models\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is OpenAI?\",\n",
      "  \"response\": \"OpenAI is an artificial intelligence research organization focused on developing and promoting friendly AI.\",\n",
      "  \"answer\": \"A company that creates Large Language Models\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: You are an expert professor specialized in grading students' answers to questions.\\nHuman: You are grading the following question:\\n    What is OpenAI?\\n    Here is the real answer:\\n    A company that creates Large Language Models\\n    You are grading the following predicted answer:\\n    OpenAI is an artificial intelligence research organization focused on developing and promoting friendly AI.\"\n",
      "  ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] [523ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"grade\\\":\\\"CORRECT\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"grade\\\":\\\"CORRECT\\\"}\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"parsed\": {\n",
      "                \"lc\": 1,\n",
      "                \"type\": \"not_implemented\",\n",
      "                \"id\": [\n",
      "                  \"__main__\",\n",
      "                  \"CorrectnessEvaluator\"\n",
      "                ],\n",
      "                \"repr\": \"CorrectnessEvaluator(grade='CORRECT')\"\n",
      "              },\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 6,\n",
      "                \"prompt_tokens\": 161,\n",
      "                \"total_tokens\": 167,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "              \"system_fingerprint\": \"fp_34a54ae93c\",\n",
      "              \"id\": \"chatcmpl-BctK7Ecbw1AFXLJTpAzFPe6NvKpgx\",\n",
      "              \"service_tier\": \"default\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run--5d81de4f-37e9-42f9-ab7d-e3053f6b42e8-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 161,\n",
      "              \"output_tokens\": 6,\n",
      "              \"total_tokens\": 167,\n",
      "              \"input_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"cache_read\": 0\n",
      "              },\n",
      "              \"output_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"reasoning\": 0\n",
      "              }\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 6,\n",
      "      \"prompt_tokens\": 161,\n",
      "      \"total_tokens\": 167,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "    \"system_fingerprint\": \"fp_34a54ae93c\",\n",
      "    \"id\": \"chatcmpl-BctK7Ecbw1AFXLJTpAzFPe6NvKpgx\",\n",
      "    \"service_tier\": \"default\"\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableLambda] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [531ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is LangChain?\",\n",
      "  \"response\": \"LangChain is a framework for developing applications powered by language models.\",\n",
      "  \"answer\": \"A framework for building LLM applications\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is LangChain?\",\n",
      "  \"response\": \"LangChain is a framework for developing applications powered by language models.\",\n",
      "  \"answer\": \"A framework for building LLM applications\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: You are an expert professor specialized in grading students' answers to questions.\\nHuman: You are grading the following question:\\n    What is LangChain?\\n    Here is the real answer:\\n    A framework for building LLM applications\\n    You are grading the following predicted answer:\\n    LangChain is a framework for developing applications powered by language models.\"\n",
      "  ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:02,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] [438ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"grade\\\":\\\"CORRECT\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"grade\\\":\\\"CORRECT\\\"}\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"parsed\": {\n",
      "                \"lc\": 1,\n",
      "                \"type\": \"not_implemented\",\n",
      "                \"id\": [\n",
      "                  \"__main__\",\n",
      "                  \"CorrectnessEvaluator\"\n",
      "                ],\n",
      "                \"repr\": \"CorrectnessEvaluator(grade='CORRECT')\"\n",
      "              },\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 6,\n",
      "                \"prompt_tokens\": 158,\n",
      "                \"total_tokens\": 164,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "              \"system_fingerprint\": \"fp_34a54ae93c\",\n",
      "              \"id\": \"chatcmpl-BctK8w2dxfR4Oew73lZs3trIC5kHZ\",\n",
      "              \"service_tier\": \"default\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run--366ef5ec-23cd-4065-84e6-0cd34b631820-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 158,\n",
      "              \"output_tokens\": 6,\n",
      "              \"total_tokens\": 164,\n",
      "              \"input_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"cache_read\": 0\n",
      "              },\n",
      "              \"output_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"reasoning\": 0\n",
      "              }\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 6,\n",
      "      \"prompt_tokens\": 158,\n",
      "      \"total_tokens\": 164,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "    \"system_fingerprint\": \"fp_34a54ae93c\",\n",
      "    \"id\": \"chatcmpl-BctK8w2dxfR4Oew73lZs3trIC5kHZ\",\n",
      "    \"service_tier\": \"default\"\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableLambda] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [445ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is LangSmith?\",\n",
      "  \"response\": \"LangSmith is a platform designed for building and deploying language models.\",\n",
      "  \"answer\": \"A platform for observing and evaluating LLM applications\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is LangSmith?\",\n",
      "  \"response\": \"LangSmith is a platform designed for building and deploying language models.\",\n",
      "  \"answer\": \"A platform for observing and evaluating LLM applications\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: You are an expert professor specialized in grading students' answers to questions.\\nHuman: You are grading the following question:\\n    What is LangSmith?\\n    Here is the real answer:\\n    A platform for observing and evaluating LLM applications\\n    You are grading the following predicted answer:\\n    LangSmith is a platform designed for building and deploying language models.\"\n",
      "  ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:03,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] [578ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"grade\\\":\\\"INCORRECT\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"grade\\\":\\\"INCORRECT\\\"}\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"parsed\": {\n",
      "                \"lc\": 1,\n",
      "                \"type\": \"not_implemented\",\n",
      "                \"id\": [\n",
      "                  \"__main__\",\n",
      "                  \"CorrectnessEvaluator\"\n",
      "                ],\n",
      "                \"repr\": \"CorrectnessEvaluator(grade='INCORRECT')\"\n",
      "              },\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 7,\n",
      "                \"prompt_tokens\": 160,\n",
      "                \"total_tokens\": 167,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "              \"system_fingerprint\": \"fp_34a54ae93c\",\n",
      "              \"id\": \"chatcmpl-BctK93LbYWMTWMioXFpGX95xWkJLA\",\n",
      "              \"service_tier\": \"default\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run--8d2edeb5-cd7b-4be2-88a2-b0645f46befa-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 160,\n",
      "              \"output_tokens\": 7,\n",
      "              \"total_tokens\": 167,\n",
      "              \"input_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"cache_read\": 0\n",
      "              },\n",
      "              \"output_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"reasoning\": 0\n",
      "              }\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 7,\n",
      "      \"prompt_tokens\": 160,\n",
      "      \"total_tokens\": 167,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "    \"system_fingerprint\": \"fp_34a54ae93c\",\n",
      "    \"id\": \"chatcmpl-BctK93LbYWMTWMioXFpGX95xWkJLA\",\n",
      "    \"service_tier\": \"default\"\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableLambda] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [586ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is Google?\",\n",
      "  \"response\": \"Google is a multinational technology company specializing in Internet-related services and products, including search engines, online advertising, and cloud computing.\",\n",
      "  \"answer\": \"A technology company known for search\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is Google?\",\n",
      "  \"response\": \"Google is a multinational technology company specializing in Internet-related services and products, including search engines, online advertising, and cloud computing.\",\n",
      "  \"answer\": \"A technology company known for search\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: You are an expert professor specialized in grading students' answers to questions.\\nHuman: You are grading the following question:\\n    What is Google?\\n    Here is the real answer:\\n    A technology company known for search\\n    You are grading the following predicted answer:\\n    Google is a multinational technology company specializing in Internet-related services and products, including search engines, online advertising, and cloud computing.\"\n",
      "  ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:04,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] [615ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"grade\\\":\\\"CORRECT\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"grade\\\":\\\"CORRECT\\\"}\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"parsed\": {\n",
      "                \"lc\": 1,\n",
      "                \"type\": \"not_implemented\",\n",
      "                \"id\": [\n",
      "                  \"__main__\",\n",
      "                  \"CorrectnessEvaluator\"\n",
      "                ],\n",
      "                \"repr\": \"CorrectnessEvaluator(grade='CORRECT')\"\n",
      "              },\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 6,\n",
      "                \"prompt_tokens\": 168,\n",
      "                \"total_tokens\": 174,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "              \"system_fingerprint\": \"fp_34a54ae93c\",\n",
      "              \"id\": \"chatcmpl-BctKAe1YxVkQwKrQOYplzJ1ayFjl5\",\n",
      "              \"service_tier\": \"default\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run--400e84b0-1c19-4760-b69f-2c8c58a22827-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 168,\n",
      "              \"output_tokens\": 6,\n",
      "              \"total_tokens\": 174,\n",
      "              \"input_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"cache_read\": 0\n",
      "              },\n",
      "              \"output_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"reasoning\": 0\n",
      "              }\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 6,\n",
      "      \"prompt_tokens\": 168,\n",
      "      \"total_tokens\": 174,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "    \"system_fingerprint\": \"fp_34a54ae93c\",\n",
      "    \"id\": \"chatcmpl-BctKAe1YxVkQwKrQOYplzJ1ayFjl5\",\n",
      "    \"service_tier\": \"default\"\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableLambda] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [624ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is Mistral?\",\n",
      "  \"response\": \"Mistral is a type of wind that occurs in southern France, characterized by its strong, cold, and dry nature.\",\n",
      "  \"answer\": \"A company that creates Large Language Models\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is Mistral?\",\n",
      "  \"response\": \"Mistral is a type of wind that occurs in southern France, characterized by its strong, cold, and dry nature.\",\n",
      "  \"answer\": \"A company that creates Large Language Models\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: You are an expert professor specialized in grading students' answers to questions.\\nHuman: You are grading the following question:\\n    What is Mistral?\\n    Here is the real answer:\\n    A company that creates Large Language Models\\n    You are grading the following predicted answer:\\n    Mistral is a type of wind that occurs in southern France, characterized by its strong, cold, and dry nature.\"\n",
      "  ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:05,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] [636ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"grade\\\":\\\"INCORRECT\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"grade\\\":\\\"INCORRECT\\\"}\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"parsed\": {\n",
      "                \"lc\": 1,\n",
      "                \"type\": \"not_implemented\",\n",
      "                \"id\": [\n",
      "                  \"__main__\",\n",
      "                  \"CorrectnessEvaluator\"\n",
      "                ],\n",
      "                \"repr\": \"CorrectnessEvaluator(grade='INCORRECT')\"\n",
      "              },\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 7,\n",
      "                \"prompt_tokens\": 171,\n",
      "                \"total_tokens\": 178,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "              \"system_fingerprint\": \"fp_34a54ae93c\",\n",
      "              \"id\": \"chatcmpl-BctKC6UieF1owSHqsJTeAcYWmieXR\",\n",
      "              \"service_tier\": \"default\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run--c2d9b79c-ceca-4516-bd17-9b519e6a48bc-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 171,\n",
      "              \"output_tokens\": 7,\n",
      "              \"total_tokens\": 178,\n",
      "              \"input_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"cache_read\": 0\n",
      "              },\n",
      "              \"output_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"reasoning\": 0\n",
      "              }\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 7,\n",
      "      \"prompt_tokens\": 171,\n",
      "      \"total_tokens\": 178,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "    \"system_fingerprint\": \"fp_34a54ae93c\",\n",
      "    \"id\": \"chatcmpl-BctKC6UieF1owSHqsJTeAcYWmieXR\",\n",
      "    \"service_tier\": \"default\"\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableLambda] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [644ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:06,  1.23s/it]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'ExperimentResults' object has no attribute 'results'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[112]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtest_length_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[111]\u001b[39m\u001b[32m, line 51\u001b[39m, in \u001b[36mtest_length_score\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     49\u001b[39m \u001b[33m\"\u001b[39m\u001b[33mTest that the length of the score is at least 80\u001b[39m\u001b[33m%\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     50\u001b[39m experiment_results = client.evaluate(ls_target, data=dataset_name, evaluators=[concision, correctness])\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m scores = [result.score \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m \u001b[43mexperiment_results\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresults\u001b[49m]\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28msum\u001b[39m(scores) / \u001b[38;5;28mlen\u001b[39m(scores) >= \u001b[32m0.8\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mThe average score is less than 80\u001b[39m\u001b[33m%\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mAttributeError\u001b[39m: 'ExperimentResults' object has no attribute 'results'"
     ]
    }
   ],
   "source": [
    "test_length_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd7ac44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7507b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1423c665",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3e8e9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734c2979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEW PROJECT BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a345cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, import the required packages\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import nest_asyncio\n",
    "from langchain.globals import set_debug, set_verbose\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Set debug and verbose mode\n",
    "set_debug(True)\n",
    "set_verbose(True)\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Get environment variables\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "LANGSMITH_TRACING = os.getenv(\"LANGSMITH_TRACING\")\n",
    "LANGSMITH_ENDPOINT = os.getenv(\"LANGSMITH_ENDPOINT\")\n",
    "LANGSMITH_API_KEY = os.getenv(\"LANGSMITH_API_KEY\")\n",
    "LANGSMITH_PROJECT = os.getenv(\"LANGSMITH_PROJECT\")\n",
    "ANTHROPIC_API_KEY = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "\n",
    "# Set environment variables\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "os.environ[\"LANGSMITH_TRACING\"] = LANGSMITH_TRACING\n",
    "os.environ[\"LANGSMITH_ENDPOINT\"] = LANGSMITH_ENDPOINT\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = LANGSMITH_API_KEY\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = LANGSMITH_PROJECT\n",
    "os.environ[\"TAVILY_API_KEY\"] = TAVILY_API_KEY\n",
    "os.environ[\"ANTHROPIC_API_KEY\"] = ANTHROPIC_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "01c2360c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded and saved as Chinook.db\n"
     ]
    }
   ],
   "source": [
    "# backtesting vs particualr datsets\n",
    "# new datset iwth prod data\n",
    "# not all evals on reference data \n",
    "# here back testing is a way to test\n",
    "# feedback is a form of gropujnd truth \n",
    "\n",
    "# use case of naviagting a digital music store - so enterpreise co pilots or chat bots\n",
    "# baisclaly they are digital apps avialabel which ewe enhancing with bots to do things autoamtically on users behlf and with naturla lkangauge interaface\n",
    "\n",
    "# final resposne trakaecotry each individual step\n",
    "import requests\n",
    "\n",
    "url = \"https://storage.googleapis.com/benchmarks-artifacts/chinook/Chinook.db\"\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    # Open a local file in binary write mode\n",
    "    with open(\"chinook.db\", \"wb\") as file:\n",
    "        # Write the content of the response (the file) to the local file\n",
    "        file.write(response.content)\n",
    "    print(\"File downloaded and saved as Chinook.db\")\n",
    "else:\n",
    "    print(f\"Failed to download the file. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "546eb495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# itneracitosn for agent\n",
    "# mock\n",
    "# query paremters determiend by llm vs given by user or from chat \n",
    "# dict and float\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "@tool\n",
    "def _refund(invoice_id: int | None, invoice_line_ids: list[int] | None, mock: bool = False) -> float:\n",
    "    \"\"\"Given an Invoice ID and/or Invoice Line IDs, delete the relevant Invoice/InvoiceLine records in the Chinook DB.\n",
    "\n",
    "    Args:\n",
    "        invoice_id: The Invoice to delete.\n",
    "        invoice_line_ids: The Invoice Lines to delete.\n",
    "        mock: If True, do not actually delete the specified Invoice/Invoice Lines. Used for testing purposes.\n",
    "\n",
    "    Returns:\n",
    "        float: The total dollar amount that was deleted (or mock deleted).\n",
    "    \"\"\"\n",
    "\n",
    "    if invoice_id is None and invoice_line_ids is None:\n",
    "        return 0.0\n",
    "\n",
    "    # Connect to the Chinook database\n",
    "    conn = sqlite3.connect(\"chinook.db\")\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    total_refund = 0.0\n",
    "\n",
    "    try:\n",
    "        # If invoice_id is provided, delete entire invoice and its lines\n",
    "        if invoice_id is not None:\n",
    "            # First get the total amount for the invoice\n",
    "            cursor.execute(\n",
    "                \"\"\"\n",
    "                SELECT Total\n",
    "                FROM Invoice\n",
    "                WHERE InvoiceId = ?\n",
    "            \"\"\",\n",
    "                (invoice_id,),\n",
    "            )\n",
    "\n",
    "            result = cursor.fetchone()\n",
    "            if result:\n",
    "                total_refund += result[0]\n",
    "\n",
    "            # Delete invoice lines first (due to foreign key constraints)\n",
    "            if not mock:\n",
    "                cursor.execute(\n",
    "                    \"\"\"\n",
    "                    DELETE FROM InvoiceLine\n",
    "                    WHERE InvoiceId = ?\n",
    "                \"\"\",\n",
    "                    (invoice_id,),\n",
    "                )\n",
    "\n",
    "                # Then delete the invoice\n",
    "                cursor.execute(\n",
    "                    \"\"\"\n",
    "                    DELETE FROM Invoice\n",
    "                    WHERE InvoiceId = ?\n",
    "                \"\"\",\n",
    "                    (invoice_id,),\n",
    "                )\n",
    "\n",
    "        # If specific invoice lines are provided\n",
    "        if invoice_line_ids is not None:\n",
    "            # Get the total amount for the specified invoice lines\n",
    "            placeholders = \",\".join([\"?\" for _ in invoice_line_ids])\n",
    "            cursor.execute(\n",
    "                f\"\"\"\n",
    "                SELECT SUM(UnitPrice * Quantity)\n",
    "                FROM InvoiceLine\n",
    "                WHERE InvoiceLineId IN ({placeholders})\n",
    "            \"\"\",\n",
    "                invoice_line_ids,\n",
    "            )\n",
    "\n",
    "            result = cursor.fetchone()\n",
    "            if result and result[0]:\n",
    "                total_refund += result[0]\n",
    "\n",
    "            if not mock:\n",
    "                # Delete the specified invoice lines\n",
    "                cursor.execute(\n",
    "                    f\"\"\"\n",
    "                    DELETE FROM InvoiceLine\n",
    "                    WHERE InvoiceLineId IN ({placeholders})\n",
    "                \"\"\",\n",
    "                    invoice_line_ids,\n",
    "                )\n",
    "\n",
    "        # Commit the changes\n",
    "        conn.commit()\n",
    "\n",
    "    except sqlite3.Error as e:\n",
    "        # Roll back in case of error\n",
    "        conn.rollback()\n",
    "        raise e\n",
    "\n",
    "    finally:\n",
    "        # Close the connection\n",
    "        conn.close()\n",
    "\n",
    "    return float(total_refund)\n",
    "\n",
    "@tool\n",
    "def _lookup(\n",
    "    customer_first_name: str,\n",
    "    customer_last_name: str,\n",
    "    customer_phone: str,\n",
    "    track_name: str | None,\n",
    "    album_title: str | None,\n",
    "    artist_name: str | None,\n",
    "    purchase_date_iso_8601: str | None,\n",
    ") -> list[dict]:\n",
    "    \"\"\"Find all of the Invoice Line IDs in the Chinook DB for the given filters.\n",
    "\n",
    "    Returns:\n",
    "        a list of dictionaries that contain keys: {\n",
    "            'invoice_line_id',\n",
    "            'track_name',\n",
    "            'artist_name',\n",
    "            'purchase_date',\n",
    "            'quantity_purchased',\n",
    "            'price_per_unit'\n",
    "        }\n",
    "    \"\"\"\n",
    "\n",
    "    # Connect to the database\n",
    "    conn = sqlite3.connect(\"chinook.db\")\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Base query joining all necessary tables\n",
    "    query = \"\"\"\n",
    "    SELECT\n",
    "        il.InvoiceLineId,\n",
    "        t.Name as track_name,\n",
    "        art.Name as artist_name,\n",
    "        i.InvoiceDate as purchase_date,\n",
    "        il.Quantity as quantity_purchased,\n",
    "        il.UnitPrice as price_per_unit\n",
    "    FROM InvoiceLine il\n",
    "    JOIN Invoice i ON il.InvoiceId = i.InvoiceId\n",
    "    JOIN Customer c ON i.CustomerId = c.CustomerId\n",
    "    JOIN Track t ON il.TrackId = t.TrackId\n",
    "    JOIN Album alb ON t.AlbumId = alb.AlbumId\n",
    "    JOIN Artist art ON alb.ArtistId = art.ArtistId\n",
    "    WHERE c.FirstName = ?\n",
    "    AND c.LastName = ?\n",
    "    AND c.Phone = ?\n",
    "    \"\"\"\n",
    "\n",
    "    # Parameters for the query\n",
    "    params = [customer_first_name, customer_last_name, customer_phone]\n",
    "\n",
    "    # Add optional filters\n",
    "    if track_name:\n",
    "        query += \" AND t.Name = ?\"\n",
    "        params.append(track_name)\n",
    "\n",
    "    if album_title:\n",
    "        query += \" AND alb.Title = ?\"\n",
    "        params.append(album_title)\n",
    "\n",
    "    if artist_name:\n",
    "        query += \" AND art.Name = ?\"\n",
    "        params.append(artist_name)\n",
    "\n",
    "    if purchase_date_iso_8601:\n",
    "        query += \" AND date(i.InvoiceDate) = date(?)\"\n",
    "        params.append(purchase_date_iso_8601)\n",
    "\n",
    "    # Execute query\n",
    "    cursor.execute(query, params)\n",
    "\n",
    "    # Fetch results\n",
    "    results = cursor.fetchall()\n",
    "\n",
    "    # Convert results to list of dictionaries\n",
    "    output = []\n",
    "    for row in results:\n",
    "        output.append(\n",
    "            {\n",
    "                \"invoice_line_id\": row[0],\n",
    "                \"track_name\": row[1],\n",
    "                \"artist_name\": row[2],\n",
    "                \"purchase_date\": row[3],\n",
    "                \"quantity_purchased\": row[4],\n",
    "                \"price_per_unit\": row[5],\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # Close connection\n",
    "    conn.close()\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9410efc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrraction in cusotmer suppoer tusually first node - not coming from config etc or get memory from there\n",
    "# route to paths to workflwo siwth on tools and prompts\n",
    "# threee paths - this routign changes in mutli agent - not just skill based workflows and agent\n",
    "# but dlegation and coollaboration\n",
    "# with messages queue\n",
    "# build more \n",
    "# sufficient detaisl check - promtp to do that \n",
    "# If we can extract info based on intent\n",
    "# and tell them what they dont have etc \n",
    "# Resposne Path \n",
    "# Maybe dont do fucniton call just have output strucutred then pass to tool node \n",
    "# extracted info \n",
    "# response\n",
    "# keep track of produc tinfo etc in the state not jsut messges so that its easy to take it out from state\n",
    "# extracting info in system message or from state have a tool to get it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f0965e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ############### OLD APPROACH\n",
    "# from typing import TypedDict, Union, NotRequired\n",
    "# class InvoiceIdOnly(TypedDict):\n",
    "#     \"\"\"Mandatory fields for refunding an invoice.\"\"\"\n",
    "#     invoice_id: int = Field(description=\"The ID of the invoice to refund.\")\n",
    "#     invoice_line_ids: NotRequired[list[int]] = Field(\n",
    "#         description=\"A list of Invoice Line IDs to refund. If provided, the invoice will be refunded for these specific lines only.\"\n",
    "#     )\n",
    "\n",
    "# class InvoiceLineIdsOnly(TypedDict):\n",
    "#     invoice_id: NotRequired[int] = Field(\n",
    "#         description=\"The ID of the invoice to refund.\"\n",
    "#     )\n",
    "#     invoice_line_ids: list[int] = Field(\n",
    "#         description=\"A list of Invoice Line IDs to refund. If provided, the invoice will be refunded for these specific lines only.\"\n",
    "#     )\n",
    "\n",
    "# class BothFields(TypedDict):\n",
    "#     invoice_id: int = Field(description=\"The ID of the invoice to refund.\")\n",
    "#     invoice_line_ids: list[int] = Field(\n",
    "#         description=\"A list of Invoice Line IDs to refund. If provided, the invoice will be refunded for these specific lines only.\"\n",
    "#     )\n",
    "\n",
    "# RefundMandatoryFields = Union[InvoiceIdOnly, InvoiceLineIdsOnly, BothFields]\n",
    "\n",
    "# class LookupMandatoryFields(TypedDict):\n",
    "#     customer_first_name: str = Field(description=\"The first name of the customer.\")\n",
    "#     customer_last_name: str = Field(description=\"The last name of the customer.\")\n",
    "#     customer_phone: str = Field(description=\"The phone number of the customer.\")\n",
    "\n",
    "# class TextResponse(TypedDict):\n",
    "#     \"\"\"Response from the Router Agent.\"\"\"\n",
    "#     response: str\n",
    "\n",
    "# class RouterAgentResponse(TypedDict):\n",
    "#     \"\"\"Response from the Router Agent.\"\"\"\n",
    "#     user_intent: str\n",
    "#     extracted_fields_or_response: Union[RefundMandatoryFields, LookupMandatoryFields, TextResponse]\n",
    "\n",
    "# workflow.add_node(\"capture_intent\")\n",
    "# workflow.add_node(\"extract_info\", extract_info)\n",
    "\n",
    "####################################\n",
    "\n",
    "from langgraph.graph.message import MessagesState\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "class State(MessagesState):\n",
    "    input: str\n",
    "\n",
    "def router(state: State) -> State:\n",
    "    system_prompt_tempalte = \"\"\"You are an expert customer support router agent. \n",
    "    You are the entry point to the customer support system.\n",
    "    You interact with the user to understand their intent, extract relevant information and fulfill the request.\n",
    "    Your task is to determine the user's intent, extract the necessary information based on that intent, call tools to gather information and respond back to the user.\n",
    "    You have access to the following tools, which represent agents that have have those specific skills and can execute those workflows:\n",
    "    1. Refund Tool: Use this tool to refund an invoice or specific invoice lines.\n",
    "    2. Lookup Tool: Use this tool to look up invoice lines based on customer information.\n",
    "    Use a tool if you have enough of the Required Fields of that tool to use it, extracted from the user input and if the intent of the user is to perform that particular function. Both must be present for you to be able to use the tool.\n",
    "    If the user intent suggests using a tool, but you do not have enough mandatory information, respond back to the user specifying what information is missing.\n",
    "    If the user intent is outside the skill sets which you can route to, respond with a message that you cannot help with that. And that only specific requests are possible.\n",
    "    Do not assist in any other way that is outside your skillset of using these tools, responding back regarding those tools if intent matches, or indicating that you do not take up any other requests.\n",
    "    If you have enough information to fulfill the request, respond back to the user answering their question or confirming that you have executed the request.\"\"\"\n",
    "\n",
    "    tools = [_refund, _lookup]\n",
    "\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.0)\n",
    "\n",
    "    llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "    prompt_template = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_prompt_tempalte),\n",
    "        (\"user\", \"{input}\"),\n",
    "    ])\n",
    "\n",
    "    router_runnable = prompt_template | llm_with_tools\n",
    "\n",
    "    message = router_runnable.invoke({\"input\": state[\"input\"]})\n",
    "\n",
    "    return {\"messages\": [message]}\n",
    "\n",
    "# def response_node(state: State) -> State:\n",
    "\n",
    "workflow = StateGraph(State)\n",
    "workflow.add_node(\"router\", router)\n",
    "workflow.add_node(\"tools\", ToolNode(tools))\n",
    "workflow.add_edge(START, \"router\")\n",
    "workflow.add_edge(\"router\", END)\n",
    "workflow.add_conditional_edges(\n",
    "    \"router\",\n",
    "    tools_condition,\n",
    "    {\n",
    "        \"tools\": \"tools\",\n",
    "        END: END,\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"tools\", \"router\")\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": 1}}\n",
    "checkpointer = Checkpointer(workflow, config=config)\n",
    "\n",
    "workflow.compile(checkpointer=Checkpointer)\n",
    "\n",
    "\n",
    "# nto really an agent - more like a workflow - why doi we need extracted tool call info \n",
    "# to store separately \n",
    "# react agent vs workflows becuase we know the paths well?\n",
    "# put the heavy liftign to the pormpt not to our design as that makes it very hard\n",
    "# more tesitn  can be done with evalautors but less dynamic and becoems workflow like - hard to maintain\n",
    "# only when you know the predicatbilty very well - architect the system well in that case\n",
    "# maybe start alwys deifning promtp tepalte\n",
    "# messages for sceanriso that build up the state in list in more than oen tthread \n",
    "# dotn ahve lsits\n",
    "# no strucutred output \n",
    "# need guardraisls\n",
    "# store the tools fields so can use or use memory to do that langmem etc \n",
    "# authrosiation and authentication etc \n",
    "# do not have to ahve intor messge on the message hist - thats input side - outside app\n",
    "# must see ienoguh apps as well to gain intutiuioon of what needed on app side\n",
    "# need to build a lot of apps to get the intuition of what is needed\n",
    "# threades of takign user inpout or succive calls are not really agentic or with human in the loop\n",
    "# ro interrupts for tools can use btu thats separte part of agent \n",
    "# those toerhs are seprate thresads and memory must be used in those scnearios\n",
    "# buidl this out and evaluate it \n",
    "# see all I can do \n",
    "# started witha nd idea now wwant to change it is abosltuely fine \n",
    "# dotn get frsutrated to change idea and dont always look at the time\n",
    "# keep going \n",
    "# add bells whistles includign memeory and try evalaute \n",
    "# sairam\n",
    "# simple agent \n",
    "# then can scale agent\n",
    "# sairam\n",
    "# steps can be combined into rotuers etc when we start noticing power of promtps\n",
    "# add all I learnt to a project\n",
    "# sairam\n",
    "# do it each day \n",
    "# sairam\n",
    "# learn somethign new each day \n",
    "# dont do refactor not so improtnat stuff now - later - now BUILD BUILD BUILD - SHIP SHIP SHIP - SHARE SHARE SHARE - SAIRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690af5ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
